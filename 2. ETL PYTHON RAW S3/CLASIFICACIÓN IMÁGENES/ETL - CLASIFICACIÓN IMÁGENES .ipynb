{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNWmRy2LC+LhqJG2laYCa4m"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### 1. Procesamiento y entendimiento de la data:"],"metadata":{"id":"MwlXYKQSZSMZ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"EWBjsDJiTpIP"},"outputs":[],"source":["# Ruta de la carpeta con las fotos\n","carpeta = \"C:/Users/lriverosq/Downloads/FOTOS\"\n","file_path = \"C:/Users/lriverosq/Downloads/BD_Instagram.csv\"\n","\n","# Obtener la lista de archivos en la carpeta\n","archivos = os.listdir(carpeta)\n","bd_imagen = pd.read_csv(file_path, sep = \";\")\n","\n","bd_imagen.columns = bd_imagen.columns.str.strip()\n","bd_imagen.columns = bd_imagen.columns.str.replace('á', 'a').str.replace('é', 'e').str.replace('í', 'i').str.replace('ó', 'o').str.replace('ú', 'u').str.replace('Á', 'A').str.replace('É', 'E').str.replace('Í', 'I').str.replace('Ó', 'O').str.replace('Ú', 'U')  # Reemplazar tildes"]},{"cell_type":"code","source":["# Verificar si hay valores NaN en la primera columna\n","print(\"Valores nulos:\", bd_imagen.isnull().sum())\n","\n","# Contar todas las filas incluyendo nulas\n","print(\"Tamaño del dataframe:\", len(bd_imagen.index))"],"metadata":{"id":"zfJQNu2mZVpX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Se cuenta con un dataframe con 4598 registros, con 21 variables diferentes, de las cuales NOMBRE y ÁREA son nuestras variables de interes, siendo NOMBRE la variable que utilizaremos para relacionarla con las imagenes que vamos a procesar y ÁREA donde tenemos las clasificaciones de las imagenes para utilizarlas en nuestro modelo no supervisado, estas variables no cuentan con datos faltantes.\n","\n","Se crea otro dataframe df_imagen (dataframe que se utilizara en todo el procesamiento) que contiene una columna con el nombre de las imagenes (NOMBRE) y otra con la ruta de cada imágen (IMÁGEN):"],"metadata":{"id":"q5mTuSCIZaJ_"}},{"cell_type":"code","source":["imagenes = [archivo for archivo in archivos if archivo.lower().endswith(('.jpg'))]\n","\n","# Crear listas para almacenar los nombres y las imágenes\n","imagenes_cargadas = []\n","\n","# Cargar imágenes y nombres en las listas\n","for imagen in imagenes:\n","    ruta_imagen = os.path.join(carpeta, imagen)\n","\n","    imagenes_cargadas.append(ruta_imagen)\n","\n","# Se crea dataframe con las imagenes y los nombres de cada imágen\n","df_imagen = pd.DataFrame({\n","    'NOMBRE': imagenes,\n","    'IMAGEN': imagenes_cargadas\n","})\n","\n","df_imagen['NOMBRE'] = df_imagen['NOMBRE'].str.replace('.jpg', '', regex= False)"],"metadata":{"id":"RgQRQVFpZcS3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Se unen las dos dataframe para tener la clasificación de cada imágen si es de fotografia (producto) o marca:"],"metadata":{"id":"dUd4poKHZfqv"}},{"cell_type":"code","source":["df_imagen = pd.merge(df_imagen, bd_imagen,on = \"NOMBRE\" )\n","print(\"Tamaño del dataframe con las imagenes:\", len(df_imagen.index))\n","print(\"Valores nulos en la ruta de la imagen:\", df_imagen['IMAGEN'].isnull().sum())\n","df_imagen.head()"],"metadata":{"id":"Fbp_hvbGZgEA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Se relacionan 4369 imagenes con la información del dataframe que contiene la clasificación por lo que 229 registros no contaban con una imagen asociada, reduciendo el tamaño del dataframe."],"metadata":{"id":"yoCkwzYyZihQ"}},{"cell_type":"markdown","source":["Se procesa el tipo de formato de cada imagen de jpg a jpeg para poder procesarlas:"],"metadata":{"id":"D7XiMqtEZk4o"}},{"cell_type":"code","source":["# Convertir las imagenes a JPEG para que se puedan procesar\n","def convertir_a_jpeg(ruta):\n","    try:\n","        with Image.open(ruta) as img:\n","            nueva_ruta = ruta.replace('.jpg')\n","            img.convert('RGB').save(nueva_ruta, 'JPEG')\n","            return nueva_ruta\n","    except Exception as e:\n","        print(f\"Error al convertir: {ruta}\")\n","        return None\n","\n","df_imagen['IMAGEN'] = df_imagen['IMAGEN'].apply(lambda x: convertir_a_jpeg(x) if x.endswith('.tif') else x)"],"metadata":{"id":"kEXOFM3TZmGX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Se procesan las imagenes y se realizan las transformaciones necesarias:"],"metadata":{"id":"JGG0lLeLZnb_"}},{"cell_type":"code","source":[" # Carga y preprocesa la imagen desde una ruta\n","def cargar_y_preprocesar_imagen(ruta):\n","    try:\n","          imagen = tf.io.read_file(ruta)\n","          imagen = tf.image.decode_image(imagen, channels=1)  # Decodificar a escala de grises\n","          imagen = tf.image.resize(imagen, [100, 100])  # Ajustar al tamaño en pixeles 64 x 64\n","          imagen = tf.keras.utils.img_to_array(imagen) # Cargar array\n","          imagen = imagen / 255.0  # Normalizar a [0, 1]\n","          return imagen\n","    except Exception as e:\n","        print(f\"Error al cargar la imagen {ruta}: {e}\")\n","        return None\n","\n","\n","df_imagen['IMAGEN_COD'] = df_imagen['IMAGEN'].apply(cargar_y_preprocesar_imagen)\n","df_imagen['IMAGEN_COD'].head()"],"metadata":{"id":"byk3srDqZnxw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Obtenemos los vectores para cada imagen.\n","\n","Imagenes en escala de grises con su clasificación:"],"metadata":{"id":"Pb9JmPTRZuvv"}},{"cell_type":"code","source":["plt.figure(figsize=(10, 10))\n","\n","for i, (idx, row) in enumerate(df_imagen.head(25).iterrows()):  # Máximo 25 imágenes\n","    plt.subplot(5, 5, i + 1)\n","    plt.xticks([])\n","    plt.yticks([])\n","    plt.grid(False)\n","    plt.imshow(row['IMAGEN_COD'], cmap=plt.cm.binary)\n","    plt.xlabel(row['AREA'])\n","\n","plt.show()"],"metadata":{"id":"vFMy39iQZv1_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Se observa con que etiquetas contamos para cada una de las imagenes:"],"metadata":{"id":"MZ5KwscPZ0gH"}},{"cell_type":"code","source":["etiq = df_imagen['AREA'].unique()\n","print(\"etiquetas:\", etiq)\n","\n","df_imagen['AREA'] = df_imagen['AREA'].str.replace('mARCA','Marca') # Se hace una limpieza de las etiquetas\n","\n","etiq_recod = df_imagen['AREA'].unique()\n","print(\"etiquetas:\", etiq_recod)"],"metadata":{"id":"ZJylSdlKZ1Jv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Tamaño del dataframe:\",len(df_imagen))\n","\n","print(\"Faltantes en las imagenes:\",df_imagen['IMAGEN'].isnull().sum())\n","print(\"Faltantes en las etiquetas:\",df_imagen['AREA'].isnull().sum())"],"metadata":{"id":"wHepa8i-Z2Ln"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["conteo_etiquetas = df_imagen['AREA'].value_counts()\n","print(\"Etiqueta:\", conteo_etiquetas)\n","# Crear la gráfica\n","plt.figure(figsize=(8, 5))\n","sns.barplot(x=conteo_etiquetas.index, y=conteo_etiquetas.values, palette=\"viridis\")\n","\n","# Personalizar la gráfica\n","plt.title('Cantidad de registros por etiqueta', fontsize=16)\n","plt.xlabel('Etiqueta', fontsize=14)\n","plt.ylabel('Cantidad', fontsize=14)\n","plt.xticks(fontsize=12)\n","plt.yticks(fontsize=12)\n","\n","# Mostrar la gráfica\n","plt.show()"],"metadata":{"id":"2j0O95QJZ3MI"},"execution_count":null,"outputs":[]}]}